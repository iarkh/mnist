{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets sentencepiece pytorch-lightning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iarkh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderConfig\n",
    "\n",
    "image_size = [1280, 960]\n",
    "max_length = 768\n",
    "\n",
    "config = VisionEncoderDecoderConfig.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "config.encoder.image_size = image_size # (height, width)\n",
    "config.decoder.max_length = max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iarkh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch dataset - pixel_values (resized, padded and normalized) and labels (input ids of the targets) tensors.\n",
    "# Padding tokens are replaced by -100 (to make sure these are ignored by the loss function).\n",
    "# Tokens are added to the vocabulary of the decoder and tokenizer.\n",
    "\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from typing import Any, List, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "added_tokens = []\n",
    "\n",
    "class DonutDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Donut. This class takes a HuggingFace Dataset as input.\n",
    "\n",
    "    Each row, consists of image path(png/jpg/jpeg) and gt data (json/jsonl/txt),\n",
    "    and it will be converted into pixel_values (vectorized image) and labels (input_ids of the tokenized string).\n",
    "\n",
    "    Args:\n",
    "        dataset_name_or_path: name of dataset (available at huggingface.co/datasets) or the path containing image files and metadata.jsonl\n",
    "        max_length: the max number of tokens for the target sequences\n",
    "        split: whether to load \"train\", \"validation\" or \"test\" split\n",
    "        ignore_id: ignore_index for torch.nn.CrossEntropyLoss\n",
    "        task_start_token: the special token to be fed to the decoder to conduct the target task\n",
    "        prompt_end_token: the special token at the end of the sequences\n",
    "        sort_json_key: whether or not to sort the JSON keys\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name_or_path: str,\n",
    "        max_length: int,\n",
    "        split: str = \"train\",\n",
    "        ignore_id: int = -100,\n",
    "        task_start_token: str = \"<s>\",\n",
    "        prompt_end_token: str = None,\n",
    "        sort_json_key: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.ignore_id = ignore_id\n",
    "        self.task_start_token = task_start_token\n",
    "        self.prompt_end_token = prompt_end_token if prompt_end_token else task_start_token\n",
    "        self.sort_json_key = sort_json_key\n",
    "\n",
    "        self.dataset = load_dataset(dataset_name_or_path, split=self.split)\n",
    "        self.dataset_length = len(self.dataset)\n",
    "\n",
    "        self.gt_token_sequences = []\n",
    "        \n",
    "        for sample in self.dataset:\n",
    "            ground_truth = json.loads(sample[\"ground_truth\"])\n",
    "            if \"gt_parses\" in ground_truth:  # when multiple ground truths are available, e.g., docvqa\n",
    "                assert isinstance(ground_truth[\"gt_parses\"], list)\n",
    "                gt_jsons = ground_truth[\"gt_parses\"]\n",
    "            else:\n",
    "                assert \"gt_parse\" in ground_truth and isinstance(ground_truth[\"gt_parse\"], dict)\n",
    "                gt_jsons = [ground_truth[\"gt_parse\"]]\n",
    "\n",
    "            self.gt_token_sequences.append(\n",
    "                [\n",
    "                    self.json2token(\n",
    "                        gt_json,\n",
    "                        update_special_tokens_for_json_key=self.split == \"train\",\n",
    "                        sort_json_key=self.sort_json_key,\n",
    "                    )\n",
    "                    + processor.tokenizer.eos_token\n",
    "                    for gt_json in gt_jsons  # load json from list of json\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.add_tokens([self.task_start_token, self.prompt_end_token])\n",
    "        self.prompt_end_token_id = processor.tokenizer.convert_tokens_to_ids(self.prompt_end_token)\n",
    "\n",
    "    def json2token(self, obj: Any, update_special_tokens_for_json_key: bool = True, sort_json_key: bool = True):\n",
    "        \"\"\"\n",
    "        Convert an ordered JSON object into a token sequence\n",
    "        \"\"\"\n",
    "        if type(obj) == dict:\n",
    "            if len(obj) == 1 and \"text_sequence\" in obj:\n",
    "                return obj[\"text_sequence\"]\n",
    "            else:\n",
    "                output = \"\"\n",
    "                if sort_json_key:\n",
    "                    keys = sorted(obj.keys(), reverse=True)\n",
    "                else:\n",
    "                    keys = obj.keys()\n",
    "                for k in keys:\n",
    "                    if update_special_tokens_for_json_key:\n",
    "                        self.add_tokens([fr\"<s_{k}>\", fr\"</s_{k}>\"])\n",
    "                    output += (\n",
    "                        fr\"<s_{k}>\"\n",
    "                        + self.json2token(obj[k], update_special_tokens_for_json_key, sort_json_key)\n",
    "                        + fr\"</s_{k}>\"\n",
    "                    )\n",
    "                return output\n",
    "        elif type(obj) == list:\n",
    "            return r\"<sep/>\".join(\n",
    "                [self.json2token(item, update_special_tokens_for_json_key, sort_json_key) for item in obj]\n",
    "            )\n",
    "        else:\n",
    "            obj = str(obj)\n",
    "            if f\"<{obj}/>\" in added_tokens:\n",
    "                obj = f\"<{obj}/>\"  # for categorical special tokens\n",
    "            return obj\n",
    "\n",
    "    def add_tokens(self, list_of_tokens: List[str]):\n",
    "        \"\"\"\n",
    "        Add special tokens to tokenizer and resize the token embeddings of the decoder\n",
    "        \"\"\"\n",
    "        newly_added_num = processor.tokenizer.add_tokens(list_of_tokens)\n",
    "        if newly_added_num > 0:\n",
    "            model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
    "            added_tokens.extend(list_of_tokens)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.dataset_length\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Load image from image_path of given dataset_path and convert into input_tensor and labels\n",
    "        Convert gt data into input_ids (tokenized string)\n",
    "        Returns:\n",
    "            input_tensor : preprocessed image\n",
    "            input_ids : tokenized gt_data\n",
    "            labels : masked labels (model doesn't need to predict prompt and pad token)\n",
    "        \"\"\"\n",
    "        sample = self.dataset[idx]\n",
    "\n",
    "        # inputs\n",
    "        pixel_values = processor(sample[\"image\"], random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.squeeze()\n",
    "\n",
    "        # targets\n",
    "        target_sequence = random.choice(self.gt_token_sequences[idx])  # can be more than one, e.g., DocVQA Task 1\n",
    "        input_ids = processor.tokenizer(\n",
    "            target_sequence,\n",
    "            add_special_tokens=False,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == processor.tokenizer.pad_token_id] = self.ignore_id  # model doesn't need to predict pad token\n",
    "        # labels[: torch.nonzero(labels == self.prompt_end_token_id).sum() + 1] = self.ignore_id  # model doesn't need to predict prompt (for VQA)\n",
    "        return pixel_values, labels, target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Pillow==10.3.0 in /home/iarkh/.local/lib/python3.10/site-packages (10.3.0)\n",
      "Requirement already satisfied: nltk in /home/iarkh/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/iarkh/.local/lib/python3.10/site-packages (from nltk) (2024.5.10)\n",
      "Requirement already satisfied: joblib in /home/iarkh/.local/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /home/iarkh/.local/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Pillow==10.3.0 nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some settings differ from pretraining; namely the size of the images + no rotation required\n",
    "processor.image_processor.size = image_size[::-1] # should be (width, height)\n",
    "processor.image_processor.do_align_long_axis = False\n",
    "\n",
    "train_dataset = DonutDataset(\"naver-clova-ix/cord-v2\", max_length=max_length,\n",
    "                             split=\"train\", task_start_token=\"<s_cord-v2>\", prompt_end_token=\"<s_cord-v2>\",\n",
    "                             sort_json_key=False, # cord dataset is preprocessed, so no need for this\n",
    "                             )\n",
    "\n",
    "val_dataset = DonutDataset(\"naver-clova-ix/cord-v2\", max_length=max_length,\n",
    "                             split=\"validation\", task_start_token=\"<s_cord-v2>\", prompt_end_token=\"<s_cord-v2>\",\n",
    "                             sort_json_key=False, # cord dataset is preprocessed, so no need for this\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(['<s_cord-v2>'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LightningModule\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "from nltk import edit_distance\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "\n",
    "\n",
    "class DonutModelPLModule(pl.LightningModule):\n",
    "    def __init__(self, config, processor, model):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pixel_values, labels, _ = batch\n",
    "\n",
    "        outputs = self.model(pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
    "        pixel_values, labels, answers = batch\n",
    "        batch_size = pixel_values.shape[0]\n",
    "        # we feed the prompt to the model\n",
    "        decoder_input_ids = torch.full((batch_size, 1), self.model.config.decoder_start_token_id, device=self.device)\n",
    "\n",
    "        outputs = self.model.generate(pixel_values,\n",
    "                                   decoder_input_ids=decoder_input_ids,\n",
    "                                   max_length=max_length,\n",
    "                                   early_stopping=True,\n",
    "                                   pad_token_id=self.processor.tokenizer.pad_token_id,\n",
    "                                   eos_token_id=self.processor.tokenizer.eos_token_id,\n",
    "                                   use_cache=True,\n",
    "                                   num_beams=1,\n",
    "                                   bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n",
    "                                   return_dict_in_generate=True,)\n",
    "\n",
    "        predictions = []\n",
    "        for seq in self.processor.tokenizer.batch_decode(outputs.sequences):\n",
    "            seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(self.processor.tokenizer.pad_token, \"\")\n",
    "            seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "            predictions.append(seq)\n",
    "\n",
    "        scores = []\n",
    "        for pred, answer in zip(predictions, answers):\n",
    "            pred = re.sub(r\"(?:(?<=>) | (?=</s_))\", \"\", pred)\n",
    "            # NOT NEEDED ANYMORE\n",
    "            # answer = re.sub(r\"<.*?>\", \"\", answer, count=1)\n",
    "            answer = answer.replace(self.processor.tokenizer.eos_token, \"\")\n",
    "            scores.append(edit_distance(pred, answer) / max(len(pred), len(answer)))\n",
    "\n",
    "            if self.config.get(\"verbose\", False) and len(scores) == 1:\n",
    "                print(f\"Prediction: {pred}\")\n",
    "                print(f\"    Answer: {answer}\")\n",
    "                print(f\" Normed ED: {scores[0]}\")\n",
    "\n",
    "        self.log(\"val_edit_distance\", np.mean(scores))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # you could also add a learning rate scheduler if you want\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.config.get(\"lr\"))\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a config for training\n",
    "config = {\"max_epochs\":30,\n",
    "          \"val_check_interval\":0.2, # how many times we want to validate during an epoch\n",
    "          \"check_val_every_n_epoch\":1,\n",
    "          \"gradient_clip_val\":1.0,\n",
    "          \"num_training_samples_per_epoch\": 800,\n",
    "          \"lr\":3e-5,\n",
    "          \"train_batch_sizes\": [8],\n",
    "          \"val_batch_sizes\": [1],\n",
    "          # \"seed\":2022,\n",
    "          \"num_nodes\": 1,\n",
    "          \"warmup_steps\": 300, # 800/8*30/10, 10%\n",
    "          \"result_path\": \"./result\",\n",
    "          \"verbose\": True,\n",
    "          }\n",
    "\n",
    "model_module = DonutModelPLModule(config, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install huggingface_hub ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377030843c494206a4ee3e5429009707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log into Hugging Face to push the model into the hub. Need a token with WRITE permissions.\n",
    "# Then take the model here: https://huggingface.co/iarkh/donut-demo/tree/main\n",
    "#!huggingface-cli login\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iarkh/.local/lib/python3.10/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/iarkh/mnist/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                      | Params\n",
      "----------------------------------------------------\n",
      "0 | model | VisionEncoderDecoderModel | 201 M \n",
      "----------------------------------------------------\n",
      "201 M     Trainable params\n",
      "0         Non-trainable params\n",
      "201 M     Total params\n",
      "807.633   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb9694b5cee41309f076188f6051e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iarkh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70b6c18cbe94340b66fc110a043bc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iarkh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <s_menu><s_nm>REAL GANACHE</s_nm><s_cnt>1</s_cnt><s_price>16,500</s_price><sep/><s_nm>EGG TART</s_nm><s_cnt>1</s_cnt><s_price>13,000</s_price></s_menu><s_total><s_total_price>16,000</s_total_price><s_cashprice>45,500</s_cashprice><s_changeprice>4,500</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>REAL GANACHE</s_nm><s_cnt>1</s_cnt><s_price>16,500</s_price><sep/><s_nm>EGG TART</s_nm><s_cnt>1</s_cnt><s_price>13,000</s_price><sep/><s_nm>PIZZA TOAST</s_nm><s_cnt>1</s_cnt><s_price>16,000</s_price></s_menu><s_total><s_total_price>45,500</s_total_price><s_cashprice>50,000</s_cashprice><s_changeprice>4,500</s_changeprice></s_total>\n",
      " Normed ED: 0.2219020172910663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iarkh/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: <s_menu><s_nm>Kopi Susu Kolonel</s_nm><s_cnt>1</s_cnt><s_price>23,000</s_price></s_menu><s_total><s_total_price>23,000</s_total_price><s_cashprice>50.000</s_cashprice><s_changeprice>27.000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Kopi Susu Kolonel</s_nm><s_cnt>1</s_cnt><s_price>23.000</s_price></s_menu><s_total><s_total_price>23.000</s_total_price><s_cashprice>50.000</s_cashprice><s_changeprice>27.000</s_changeprice></s_total>\n",
      " Normed ED: 0.009345794392523364\n",
      "Prediction: <s_menu><s_nm>S-Ovaltine</s_nm><s_cnt>1</s_cnt><s_price>20,000</s_price></s_menu><s_sub_total><s_subtotal_price>1,818</s_subtotal_price><s_tax_price>18,18</s_price><sep/><s_nm>Total:</s_nm><s_cnt>1</s_cnt><s_price>10,000</s_price></s_menu><s_sub_total><s_subtotal_price>80,000</s_subtotal_price><s_tax_price>100,000</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>14,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>S-Ovaltine 50%</s_nm><s_unitprice>20,000</s_unitprice><s_cnt>1</s_cnt><s_price>20,000</s_price><s_vatyn>10% Tax Included</s_vatyn></s_menu><s_sub_total><s_subtotal_price>18,181</s_subtotal_price><s_tax_price>1,818</s_tax_price></s_sub_total><s_total><s_total_price>20,000</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>80,000</s_changeprice></s_total>\n",
      " Normed ED: 0.41504854368932037\n",
      "Prediction: <s_menu><s_nm>M-Carmel Black Tea @28.00</s_unitprice><s_cnt>1X</s_cnt><s_price>28,000</s_price></s_menu><s_sub_total><s_subtotal_price>0</s_subtotal_price><s_tax_price>28,000</s_subtotal_price><s_tax_price>28,000</s_subtotal_price><s_tax_price>28,000</s_total_price><s_cashprice>28,000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>M-Caramel Black Tea</s_nm><s_unitprice>@28,000</s_unitprice><s_cnt>1X</s_cnt><s_price>28,000</s_price><s_sub><s_nm>70%</s_nm><sep/><s_nm>Less Ice</s_nm></s_sub></s_menu><s_sub_total><s_subtotal_price>28,000</s_subtotal_price><s_tax_price>0</s_tax_price></s_sub_total><s_total><s_total_price>28,000</s_total_price><s_cashprice>28,000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      " Normed ED: 0.2810945273631841\n",
      "Prediction: <s_menu><s_nm>BBQ Chicken</s_nm><s_cnt>1</s_cnt><s_price>41,000</s_price></s_menu><s_total><s_total_price>0</s_price></s_menu><s_total><s_total_price>41,000</s_total_price><s_cashprice>41,000</s_cashprice><s_changeprice>9,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>BBQ Chicken</s_nm><s_cnt>1</s_cnt><s_price>41,000</s_price><s_sub><s_nm>Sedang</s_nm><s_cnt>1</s_cnt><s_price>0</s_price></s_sub></s_menu><s_sub_total><s_subtotal_price>41,000</s_subtotal_price></s_sub_total><s_total><s_total_price>41,000</s_total_price><s_cashprice>50.000</s_cashprice><s_changeprice>:9,000</s_changeprice><s_menuqty_cnt>1</s_menuqty_cnt></s_total>\n",
      " Normed ED: 0.35789473684210527\n",
      "Prediction: <s_menu><s_nm>LE MINERAL</s_nm><s_cnt>1.00</s_unitprice><s_cnt>1.00</s_unitprice><s_cnt>7,27</s_tax_price></s_sub_total><s_total><s_total_price>727</s_total_price><s_cashprice>8,000</s_cashprice><s_changeprice>8,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>LE MINERAL</s_nm><s_cnt>1.00</s_cnt><s_price>8,000</s_price></s_menu><s_sub_total><s_subtotal_price>7,273</s_subtotal_price><s_tax_price>727</s_tax_price></s_sub_total><s_total><s_total_price>8,000</s_total_price><s_cashprice>8,000</s_cashprice></s_total>\n",
      " Normed ED: 0.3828996282527881\n",
      "Prediction: <s_menu><s_nm>POTATO SAUSAGE BREAD</s_nm><s_cnt>1</s_cnt><s_price>19,000</s_price><sep/><s_nm>OREO GREEN TEA SPREAD</s_nm><s_cnt>1</s_cnt><s_price>52,000</s_price></s_menu><s_sub_total><s_subtotal_price>52,000</s_subtotal_price><s_tax_price>52,000</s_total_price><s_cashprice>123,000</s_cashprice><s_changeprice>123,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>POTATO SAUSAGE BREAD</s_nm><s_cnt>1</s_cnt><s_price>19,000</s_price><sep/><s_nm>OREO GREEN TEA SPREAD</s_nm><s_cnt>1</s_cnt><s_price>52,000</s_price><sep/><s_nm>WHITE CHOCO BANANA SPREAD</s_nm><s_cnt>1</s_cnt><s_price>52,000</s_price></s_menu><s_total><s_total_price>123,000</s_total_price><s_creditcardprice>123,000</s_creditcardprice></s_total>\n",
      " Normed ED: 0.2972222222222222\n",
      "Prediction: <s_menu><s_nm>Choco Devil</s_nm><s_cnt>4</s_cnt><s_price>63,636</s_price><sep/><s_nm>CP 360 Club Card</s_nm><s_cnt>-9,545</s_price></s_menu><s_sub_total><s_subtotal_price>63,636</s_subtotal_price><s_tax_price>-9,545</s_tax_price></s_sub_total><s_total><s_total_price>59,500</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>40,500</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Choco Devil</s_nm><s_cnt>4</s_cnt><s_discountprice>-9,545</s_discountprice><s_price>63,636</s_price></s_menu><s_sub_total><s_subtotal_price>63,636</s_subtotal_price><s_discount_price>-9,545</s_discount_price><s_tax_price>5,409</s_tax_price></s_sub_total><s_total><s_total_price>59,500</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>40,500</s_changeprice></s_total>\n",
      " Normed ED: 0.25316455696202533\n",
      "Prediction: <s_menu><s_nm>TALAM UNGU</s_nm><s_cnt>3X</s_cnt><s_price>19,500</s_price><sep/><s_nm>DISC ITEM</s_nm><s_cnt>-40.000%</s_price><sep/><s_nm>AMOUNT</s_nm><s_cnt>1X</s_cnt><s_price>-7,800</s_price><sep/><s_nm>MIKA KECIL</s_nm><s_cnt>0</s_price></s_menu><s_sub_total><s_subtotal_price>11,700</s_subtotal_price><s_tax_price>11,700</s_tax_price></s_sub_total><s_total><s_total_price>11,700</s_total_price><s_cashprice>20,000</s_cashprice><s_changeprice>8,300</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>TALAM UNGU</s_nm><s_unitprice>@6500</s_unitprice><s_cnt>3X</s_cnt><s_discountprice>-7,800</s_discountprice><s_price>19,500</s_price><sep/><s_nm>MIKA KECIL</s_nm><s_unitprice>@0</s_unitprice><s_cnt>1X</s_cnt><s_price>0</s_price></s_menu><s_sub_total><s_subtotal_price>11,700</s_subtotal_price></s_sub_total><s_total><s_total_price>11,700</s_total_price><s_cashprice>20,000</s_cashprice><s_changeprice>8,300</s_changeprice><s_menuqty_cnt>4.00xITEMs</s_menuqty_cnt></s_total>\n",
      " Normed ED: 0.4074074074074074\n",
      "Prediction: <s_menu><s_nm>Tahu Ikan Oma Giok</s_nm><s_cnt>1</s_cnt><s_price>20.000</s_price></s_menu><s_total><s_total_price>20.000</s_total_price><s_cashprice>20.000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Tahu Ikan Oma Giok</s_nm><s_cnt>1</s_cnt><s_price>20,000</s_price></s_menu><s_total><s_total_price>20,000</s_total_price><s_cashprice>20,000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      " Normed ED: 0.014285714285714285\n",
      "Prediction: <s_menu><s_nm>Serbu 1</s_cnt><s_price>40.000</s_price></s_menu><s_total><s_total_price>20.000</s_subtotal_price><s_tax_price>40.000</s_total_price><s_cashprice>40.000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Serbu 1</s_nm><s_cnt>2</s_cnt><s_price>40.000</s_price><sep/><s_nm>Choco Peanut Bread</s_nm><s_cnt>2</s_cnt><s_price>20.000</s_price></s_menu><s_total><s_total_price>60.000</s_total_price><s_cashprice>60.000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      " Normed ED: 0.2888086642599278\n",
      "Prediction: <s_menu><s_nm>Se'I Sapi Sambal Matah ( R )</s_nm><s_cnt>1</s_cnt><s_price>20.000</s_price></s_menu><s_sub_total><s_subtotal_price>25.000</s_subtotal_price><s_tax_price>25.000</s_subtotal_price><s_tax_price>10.000</s_subtotal_price><s_tax_price>16.000</s_subtotal_price><s_tax_price>81.000</s_subtotal_price><s_tax_price>8.100</s_tax_price></s_sub_total><s_total><s_total_price>89.100</s_total_price><s_cashprice>89.100</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Se'I Sapi Sambal Matah ( R )</s_nm><s_cnt>1</s_cnt><s_price>20.000</s_price><sep/><s_nm>Se'I Sapi Lada Hitam (J)</s_nm><s_cnt>1</s_cnt><s_price>35.000</s_price><sep/><s_nm>Nasi Putih</s_nm><s_cnt>2</s_cnt><s_price>10.000</s_price><sep/><s_nm>Milk Shake Coklat</s_nm><s_cnt>1</s_cnt><s_price>16.000</s_price></s_menu><s_sub_total><s_subtotal_price>81.000</s_subtotal_price><s_tax_price>8.100</s_tax_price></s_sub_total><s_total><s_total_price>89.100</s_total_price><s_changeprice>0</s_changeprice><s_creditcardprice>89.100</s_creditcardprice></s_total>\n",
      " Normed ED: 0.3734513274336283\n",
      "Prediction: <s_menu><s_nm>ES KOPI SUSU</s_nm><s_cnt>4</s_cnt><s_price>72.000</s_price></s_menu><s_total><s_total_price>72.000</s_subtotal_price><s_tax_price>72.000</s_total_price><s_cashprice>12.000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>ES KOPI SUSU</s_nm><s_cnt>4</s_cnt><s_price>72.000</s_price></s_menu><s_total><s_total_price>72.000</s_total_price><s_changeprice>0</s_changeprice><s_emoneyprice>72.000</s_emoneyprice></s_total>\n",
      " Normed ED: 0.24380165289256198\n",
      "Prediction: <s_menu><s_nm>MINERAL 600 ML</s_nm><s_cnt>1</s_cnt><s_price>7,727</s_price><sep/><s_nm>BULGOGI RICE R</s_nm><s_cnt>1</s_cnt><s_price>33,636</s_price></s_menu><s_sub_total><s_subtotal_price>41,364</s_subtotal_price><s_tax_price>4,136</s_tax_price></s_sub_total><s_total><s_total_price>45,500</s_total_price><s_cashprice>50,000</s_cashprice><s_changeprice>-4,500</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>MINERAL 600 ML</s_nm><s_cnt>1</s_cnt><s_price>7,727</s_price><sep/><s_nm>BULGOGI RICE R</s_nm><s_cnt>1</s_cnt><s_price>33,636</s_price></s_menu><s_sub_total><s_subtotal_price>41,364</s_subtotal_price><s_tax_price>4,136</s_tax_price></s_sub_total><s_total><s_total_price>45,500</s_total_price><s_cashprice>50,000</s_cashprice><s_changeprice>-4,500</s_changeprice></s_total>\n",
      " Normed ED: 0.0\n",
      "Prediction: <s_menu><s_nm>Arem Arem ← 12.000</s_unitprice><s_cnt>2x</s_cnt><s_price>24,000</s_price><sep/><s_nm>Kroket</s_nm><s_cnt>1x @12.000</s_price></s_menu><s_sub_total><s_subtotal_price>12.000</s_subtotal_price><s_tax_price>Rp 36.000</s_subtotal_price><s_tax_price>3.600</s_tax_price></s_sub_total><s_total><s_total_price>39.600</s_total_price><s_cashprice>Rp 39.600</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Arem Arem</s_nm><s_unitprice>@ 12.000</s_unitprice><s_cnt>2 x</s_cnt><s_price>24.000</s_price><sep/><s_nm>Kroket</s_nm><s_unitprice>@ 12.000</s_unitprice><s_cnt>1 x</s_cnt><s_price>12.000</s_price></s_menu><s_sub_total><s_subtotal_price>Rp 36.000</s_subtotal_price><s_tax_price>Rp 3.600</s_tax_price></s_sub_total><s_total><s_total_price>Rp 39.600</s_total_price><s_emoneyprice>Rp 39.600</s_emoneyprice></s_total>\n",
      " Normed ED: 0.3091334894613583\n",
      "Prediction: <s_menu><s_nm>Arem Arem</s_nm><s_cnt>2</s_cnt><s_price>24.000</s_price><sep/><s_nm>Pepenero Pastel</s_nm><s_cnt>2</s_cnt><s_price>30.000</s_price></s_menu><s_sub_total><s_subtotal_price>Rp 54.000</s_subtotal_price><s_tax_price>Rp 5.400</s_subtotal_price><s_tax_price>59.400</s_tax_price></s_sub_total><s_total><s_total_price>Rp 59.400</s_total_price><s_cashprice>100.000</s_cashprice><s_changeprice>40.600</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Arem Arem</s_nm><s_unitprice>12.000</s_unitprice><s_cnt>2</s_cnt><s_price>24.000</s_price><sep/><s_nm>Pepenero Pastel</s_nm><s_unitprice>15.000</s_unitprice><s_cnt>2</s_cnt><s_price>30.000</s_price></s_menu><s_sub_total><s_subtotal_price>Rp 54.000</s_subtotal_price><s_tax_price>Rp 5.400</s_tax_price></s_sub_total><s_total><s_total_price>Rp 59.400</s_total_price><s_cashprice>Rp 100.000</s_cashprice><s_changeprice>Rp 40.600</s_changeprice></s_total>\n",
      " Normed ED: 0.23655913978494625\n",
      "Prediction: <s_menu><s_nm>TT</s_nm><s_price>20,000</s_price></s_menu><s_total><s_total_price>20.000</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>80,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>TT</s_nm><s_unitprice>20,000</s_unitprice><s_cnt>1</s_cnt><s_price>20,000</s_price></s_menu><s_total><s_total_price>20,000</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>80,000</s_changeprice></s_total>\n",
      " Normed ED: 0.2145922746781116\n",
      "Prediction: <s_menu><s_nm>LEMONADE 16OZ</s_nm><s_cnt>1 x 20.00</s_unitprice><s_cnt>1</s_cnt><s_price>20.000</s_price></s_menu><s_sub_total><s_subtotal_price>20.000</s_subtotal_price><s_tax_price>20.000</s_tax_price></s_sub_total><s_total><s_total_price>100,000</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>80,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>LEMONADE 16OZ</s_nm><s_unitprice>20,000</s_unitprice><s_cnt>1</s_cnt><s_price>20,000</s_price></s_menu><s_sub_total><s_subtotal_price>20,000</s_subtotal_price></s_sub_total><s_total><s_total_price>20,000</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>80.000</s_changeprice></s_total>\n",
      " Normed ED: 0.1391304347826087\n",
      "Prediction: <s_menu><s_nm>beef C roll 3pcs</s_nm><s_cnt>1</s_cnt><s_price>10,000</s_price></s_menu><s_total><s_total_price>15,000</s_total_price><s_cashprice>25.000</s_cashprice><s_changeprice>75,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>beef C roll 3pcs</s_nm><s_unitprice>10,000</s_unitprice><s_cnt>1</s_cnt><s_price>10,000</s_price><sep/><s_nm>kaya bred</s_nm><s_unitprice>15,000</s_unitprice><s_cnt>1</s_cnt><s_price>15,000</s_price></s_menu><s_total><s_total_price>25,000</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>75,000</s_changeprice><s_menuqty_cnt>2</s_menuqty_cnt></s_total>\n",
      " Normed ED: 0.45144356955380577\n",
      "Prediction: <s_menu><s_nm>FUTAMI 17 GREEN TEA (CLAS</s_nm><s_cnt>1</s_cnt><s_price>12,500</s_price><sep/><s_nm>EGG TART</s_nm><s_cnt>1</s_cnt><s_price>13,000</s_price></s_menu><s_total><s_total_price>17,000</s_total_price><s_cashprice>42,500</s_cashprice><s_changeprice>7,500</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>FUTAMI 17 GREEN TEA (CLAS</s_nm><s_cnt>1</s_cnt><s_price>12,500</s_price><sep/><s_nm>EGG TART</s_nm><s_cnt>1</s_cnt><s_price>13,000</s_price><sep/><s_nm>GRAIN CROQUE MONSIEUR</s_nm><s_cnt>1</s_cnt><s_price>17,000</s_price></s_menu><s_total><s_total_price>42,500</s_total_price><s_cashprice>50,000</s_cashprice><s_changeprice>7,500</s_changeprice></s_total>\n",
      " Normed ED: 0.23513513513513515\n",
      "Prediction: <s_menu><s_nm>JAMUR</s_nm><s_cnt>2</s_cnt><s_price>10,000</s_price></s_menu><s_sub_total><s_subtotal_price>15,000</s_subtotal_price><s_tax_price>15,000</s_subtotal_price><s_tax_price>1,500</s_tax_price></s_sub_total><s_total><s_total_price>16,500</s_total_price><s_cashprice>20,000</s_cashprice><s_changeprice>3,500</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>JAMUR</s_nm><s_cnt>2</s_cnt><s_price>10,000</s_price><sep/><s_nm>TAHU</s_nm><s_cnt>1</s_cnt><s_price>5,000</s_price></s_menu><s_sub_total><s_subtotal_price>15,000</s_subtotal_price><s_tax_price>1,500</s_tax_price></s_sub_total><s_total><s_total_price>16,500</s_total_price><s_cashprice>20,000</s_cashprice><s_changeprice>3,500</s_changeprice></s_total>\n",
      " Normed ED: 0.16666666666666666\n",
      "Prediction: <s_menu><s_nm>Mango Lemon Tea</s_nm><s_cnt>1</s_cnt><s_price>Rp29,090</s_price><sep/><s_nm>Sliders Set</s_nm><s_cnt>1</s_cnt><s_price>Rp113,636</s_price><sep/><s_nm>Chicken Vege Rice Bowl</s_nm><s_cnt>1</s_cnt><s_price>Rp86,363</s_price></s_menu><s_sub_total><s_subtotal_price>-Rp34,363</s_subtotal_price><s_tax_price>Rp194,726</s_tax_price></s_sub_total><s_total><s_total_price>Rp9,736</s_tax_price></s_sub_total><s_total><s_total_price>Rp20,446</s_total_price><s_cashprice>Rp224,908</s_tax_price></s_sub_total><s_total><s_total_price>Rp224,908</s_total_price><s_cashprice>\n",
      "    Answer: <s_menu><s_nm>Mango Lemon Tea</s_nm><s_cnt>1</s_cnt><s_price>Rp 29,090</s_price><sep/><s_nm>Sliders Set</s_nm><s_cnt>1</s_cnt><s_price>Rp 113,636</s_price><sep/><s_nm>Chicken Vege Rice Bowl</s_nm><s_cnt>1</s_cnt><s_price>Rp 86,363</s_price><sep/><s_nm>Discount BCA 15%</s_nm><s_cnt>1</s_cnt><s_price>-Rp 34,363</s_price></s_menu><s_sub_total><s_subtotal_price>Rp 194,726</s_subtotal_price><s_service_price>Rp 9,736</s_service_price><s_tax_price>Rp 20,446</s_tax_price></s_sub_total><s_total><s_total_price>Rp 224,908</s_total_price><s_creditcardprice>Rp 224,908</s_creditcardprice></s_total>\n",
      " Normed ED: 0.3147208121827411\n",
      "Prediction: <s_menu><s_nm>Redvelvet Nutella</s_nm><s_cnt>1</s_cnt><s_price>280,000</s_price></s_menu><s_sub_total><s_subtotal_price>280,000</s_subtotal_price><s_tax_price>28,000</s_subtotal_price><s_tax_price>28,000</s_tax_price></s_sub_total><s_total><s_total_price>308,000</s_total_price><s_cashprice>308,000</s_cashprice><s_changeprice>308.000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>RedVelvet Nutella</s_nm><s_cnt>1</s_cnt><s_price>280,000</s_price><s_sub><s_nm>Free Mini Candle</s_nm><s_cnt>.5</s_cnt><sep/><s_nm>Large Box</s_nm><s_cnt>1</s_cnt></s_sub></s_menu><s_sub_total><s_subtotal_price>280,000</s_subtotal_price><s_tax_price>28,000</s_tax_price></s_sub_total><s_total><s_total_price>308,000</s_total_price><s_creditcardprice>308,000</s_creditcardprice></s_total>\n",
      " Normed ED: 0.3740648379052369\n",
      "Prediction: <s_menu><s_nm>BUBBLE GUM</s_nm><s_cnt>1</s_cnt><s_price>18,182</s_price></s_menu><s_sub_total><s_subtotal_price>18,182</s_subtotal_price><s_tax_price>1,8182</s_subtotal_price><s_tax_price>1,8182</s_subtotal_price><s_tax_price>18,182</s_tax_price></s_sub_total><s_total><s_total_price>18,182</s_total_price><s_cashprice>19,182</s_total_price><s_cashprice>18,182</s_total_price><s_cashprice>20,000</s_cashprice><s_changeprice>20,00</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>BUBBLE GUM</s_nm><s_cnt>1</s_cnt><s_price>18,182</s_price></s_menu><s_sub_total><s_subtotal_price>18,182</s_subtotal_price><s_tax_price>1,818</s_tax_price></s_sub_total><s_total><s_total_price>20.000</s_total_price><s_cashprice>20.000</s_cashprice><s_menuqty_cnt>1</s_menuqty_cnt></s_total>\n",
      " Normed ED: 0.3912087912087912\n",
      "Prediction: <s_menu><s_nm>PAIN AU CHOCOLATE</s_nm><s_cnt>1</s_cnt><s_price>11,000</s_price><sep/><s_nm>CHOCO CUSTARD PASTRY</s_nm><s_cnt>1</s_cnt><s_price>12,000</s_price><sep/><s_nm>MILK PASTRY ROLL</s_nm><s_cnt>1</s_cnt><s_price>9,000</s_price><sep/><s_nm>REAL CHEESE INSIDE BREAD</s_nm><s_cnt>1</s_cnt><s_price>13,500</s_price><sep/><s_nm>SAUSAGE BREAD</s_nm><s_cnt>1</s_cnt><s_price>15,000</s_price></s_menu><s_sub_total><s_subtotal_price>20,000</s_subtotal_price><s_tax_price>80,500</s_subtotal_price><s_tax_price>100,000</s_total_price><s_cashprice>19,500</s_cashprice><s_changeprice>\n",
      "    Answer: <s_menu><s_nm>PAIN AU CHOCOLATE</s_nm><s_cnt>1</s_cnt><s_price>11,000</s_price><sep/><s_nm>CHOCO CUSTARD PASTRY</s_nm><s_cnt>1</s_cnt><s_price>12,000</s_price><sep/><s_nm>MILK PASTRY ROLL</s_nm><s_cnt>1</s_cnt><s_price>9,000</s_price><sep/><s_nm>REAL CHEESE INSIDE BREAD</s_nm><s_cnt>1</s_cnt><s_price>13,500</s_price><sep/><s_nm>SAUSAGE BREAD</s_nm><s_cnt>1</s_cnt><s_price>15,000</s_price><sep/><s_nm>HAM CHEESE FLAT BREAD</s_nm><s_cnt>1</s_cnt><s_price>20,000</s_price></s_menu><s_total><s_total_price>80,500</s_total_price><s_cashprice>100,000</s_cashprice><s_changeprice>19,500</s_changeprice></s_total>\n",
      " Normed ED: 0.16776315789473684\n",
      "Prediction: <s_menu><s_nm>1Prs Sop Sui Jiao</s_nm><s_cnt>1Prs Ha Kaou Udng</s_nm><s_cnt>1Prs Sio May Kpting</s_nm><s_cnt>1Prs Siomay Kmbinasi</s_nm><s_cnt>1Prs Leng Hong Kien</s_nm><s_cnt>1Prs Mic Kokung Trsi</s_nm><s_cnt>1Prs</s_cnt><s_price>28,000</s_price></s_menu><s_total><s_total_price>23,500</s_subtotal_price><s_tax_price>23,500</s_subtotal_price><s_tax_price>23,000</s_total_price><s_cashprice>30,000</s_cashprice><s_changeprice>23,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Sop Sui Jiao</s_nm><s_cnt>1Prs</s_cnt><s_price>33,000</s_price><sep/><s_nm>Ha Kaou Udng</s_nm><s_cnt>1Prs</s_cnt><s_price>28,000</s_price><sep/><s_nm>Sio May Kpting</s_nm><s_cnt>1Prs</s_cnt><s_price>23,500</s_price><sep/><s_nm>Siomay Kmbinasi</s_nm><s_cnt>1Prs</s_cnt><s_price>23,000</s_price><sep/><s_nm>Leng Hong Kien</s_nm><s_cnt>1Prs</s_cnt><s_price>30,000</s_price><sep/><s_nm>Mie Trsi Kgkung</s_nm><s_cnt>1Prs</s_cnt><s_price>35,500</s_price><sep/><s_nm>Es Teh Tawar</s_nm><s_cnt>1Gls</s_cnt><s_price>7,000</s_price></s_menu><s_sub_total><s_subtotal_price>180,000</s_subtotal_price><s_service_price>9,000</s_service_price><s_tax_price>18,900</s_tax_price></s_sub_total><s_total><s_total_price>207,900</s_total_price><s_menutype_cnt>7</s_menutype_cnt><s_menuqty_cnt>7</s_menuqty_cnt></s_total>\n",
      " Normed ED: 0.5344827586206896\n",
      "Prediction: <s_menu><s_nm>NASI MERAH/PUTIH</s_nm><s_cnt>1x5,000</s_unitprice><s_cnt>1x</s_cnt><s_price>5,000</s_price><sep/><s_nm>SAYUR</s_nm><s_cnt>2x4.000</s_unitprice><s_cnt>2x4.000</s_subtotal_price><s_tax_price>8,000</s_tax_price></s_sub_total><s_total><s_total_price>2.000</s_total_price><s_cashprice>12.000</s_cashprice><s_changeprice>12.000</s_changeprice></s_total>1x 14.000</s_cashprice><s_changeprice>6.000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>NASI MERAH/PUTIH</s_nm><s_unitprice>5.000</s_unitprice><s_cnt>1x</s_cnt><s_price>5.000</s_price><sep/><s_nm>SAYUR</s_nm><s_unitprice>4.000</s_unitprice><s_cnt>2x</s_cnt><s_price>8.000</s_price><sep/><s_nm>KERUPUK/SAMBEL</s_nm><s_unitprice>2.000</s_unitprice><s_cnt>1x</s_cnt><s_price>2.000</s_price><sep/><s_nm>AYAM</s_nm><s_unitprice>14.000</s_unitprice><s_cnt>1x</s_cnt><s_price>14.000</s_price><sep/><s_nm>MINUMAN KEMASAN/REFILL</s_nm><s_unitprice>6.000</s_unitprice><s_cnt>1x</s_cnt><s_price>6.000</s_price></s_menu><s_total><s_total_price>Rp. 35.000</s_total_price></s_total>\n",
      " Normed ED: 0.4612794612794613\n",
      "Prediction: <s_menu><s_nm>THAI ICED TEA (L)</s_nm><s_cnt>1</s_cnt><s_price>16,363</s_price></s_menu><s_total><s_total_price>16,363</s_subtotal_price><s_tax_price>16,363</s_tax_price></s_sub_total><s_total><s_total_price>17,999</s_total_price><s_cashprice>17,999</s_cashprice><s_changeprice>\n",
      "    Answer: <s_menu><s_nm>THAI ICED TEA (L)</s_nm><s_unitprice>16,363</s_unitprice><s_cnt>1</s_cnt><s_price>16.363</s_price></s_menu><s_sub_total><s_subtotal_price>16,363</s_subtotal_price><s_tax_price>1,636</s_tax_price></s_sub_total><s_total><s_total_price>17,999</s_total_price><s_menuqty_cnt>1</s_menuqty_cnt></s_total>\n",
      " Normed ED: 0.2604501607717042\n",
      "Prediction: <s_menu><s_nm>ELEPHANT READ BEAN</s_nm><s_cnt>1</s_cnt><s_price>12,000</s_price><sep/><s_nm>chapsal twister donnut</s_nm><s_cnt>1</s_cnt><s_price>12,000</s_price></s_menu><s_total><s_total_price>10,000</s_total_price><s_cashprice>22,000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>ELEPHANT READ BEAN</s_nm><s_unitprice>12,000</s_unitprice><s_cnt>1</s_cnt><s_price>12,000</s_price><sep/><s_nm>chapsal twister donnut</s_nm><s_unitprice>10,000</s_unitprice><s_cnt>1</s_cnt><s_price>10,000</s_price></s_menu><s_total><s_total_price>22,000</s_total_price><s_cashprice>22,000</s_cashprice><s_changeprice>0</s_changeprice><s_menuqty_cnt>2</s_menuqty_cnt></s_total>\n",
      " Normed ED: 0.258974358974359\n",
      "Prediction: <s_menu><s_nm>Sabun Beras 1</s_cnt><s_price>30000</s_price></s_menu><s_sub_total><s_subtotal_price>30000</s_subtotal_price><s_tax_price>30000</s_subtotal_price><s_tax_price>30000</s_subtotal_price><s_tax_price>30000</s_tax_price></s_sub_total><s_total><s_total_price>30000</s_subtotal_price><s_tax_price>5000</s_subtotal_price><s_tax_price>20000</s_total_price><s_cashprice>20000</s_cashprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Sabun Beras</s_nm><s_unitprice>30000</s_unitprice><s_cnt>1</s_cnt><s_price>30000</s_price></s_menu><s_sub_total><s_subtotal_price>30000</s_subtotal_price><s_discount_price>Discount(0%)</s_discount_price></s_sub_total><s_total><s_cashprice>50000</s_cashprice><s_changeprice>20000</s_changeprice></s_total>\n",
      " Normed ED: 0.42431761786600497\n",
      "Prediction: <s_menu><s_nm>REDBEAN BRE/D</s_nm><s_cnt>1</s_cnt><s_price>9,000</s_price><sep/><s_nm>FRANKFRUT S/USAGE ROLL</s_nm><s_cnt>1</s_cnt><s_price>12,000</s_price></s_menu><s_total><s_total_price>21,000</s_total_price><s_cashprice>50,000</s_cashprice><s_changeprice>29,000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>REDBEAN BRE/D</s_nm><s_cnt>1</s_cnt><s_price>9,000</s_price><sep/><s_nm>FRANKFRUT S/USAGE ROLL</s_nm><s_cnt>1</s_cnt><s_price>12,000</s_price></s_menu><s_total><s_total_price>21,000</s_total_price><s_cashprice>50,000</s_cashprice><s_changeprice>29,000</s_changeprice></s_total>\n",
      " Normed ED: 0.0\n",
      "Prediction: <s_menu><s_nm>PREMIUM TOAST PAN BREAD</s_nm><s_cnt>1</s_cnt><s_price>24,000</s_price></s_menu><s_total><s_total_price>24,000</s_total_price><s_cashprice>24,000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>PREMIUM TOAST PAN BREAD</s_nm><s_cnt>1</s_cnt><s_price>24,000</s_price></s_menu><s_total><s_total_price>24,000</s_total_price><s_cashprice>24,000</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      " Normed ED: 0.0\n",
      "Prediction: <s_menu><s_nm>Nasi (MLY)</s_nm><s_cnt>1</s_cnt><s_price>6.000</s_price></s_menu><s_sub_total><s_subtotal_price>6.000</s_subtotal_price><s_tax_price>6.000</s_subtotal_price><s_tax_price>6.000</s_total_price><s_cashprice>6.000</s_cashprice><s_changeprice>6.000</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>Nasi (MLY)</s_nm><s_cnt>1</s_cnt><s_price>6.000</s_price></s_menu><s_sub_total><s_subtotal_price>6.000</s_subtotal_price></s_sub_total><s_total><s_total_price>6.000</s_total_price><s_emoneyprice>6.000</s_emoneyprice></s_total>\n",
      " Normed ED: 0.23591549295774647\n",
      "Prediction: <s_menu><s_nm>GRAINS PAN BREAD</s_nm><s_cnt>1</s_cnt><s_price>20,500</s_price><sep/><s_nm>ICED HIBISCUS LYCHEE TEA</s_nm><s_cnt>1</s_cnt><s_price>37,000</s_price></s_menu><s_sub_total><s_subtotal_price>57,500</s_subtotal_price><s_tax_price>50,000</s_total_price><s_cashprice>7,500</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      "    Answer: <s_menu><s_nm>GRAINS PAN BREAD</s_nm><s_cnt>1</s_cnt><s_price>20,500</s_price><sep/><s_nm>ICED HIBISCUS LYCHEE TEA</s_nm><s_cnt>1</s_cnt><s_price>37,000</s_price></s_menu><s_total><s_total_price>57,500</s_total_price><s_total_etc>50,000</s_total_etc><s_cashprice>7,500</s_cashprice><s_changeprice>0</s_changeprice></s_total>\n",
      " Normed ED: 0.0625\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
    "\n",
    "#wandb_logger = WandbLogger(project=\"Donut\", name=\"demo-run-cord\")\n",
    "\n",
    "class PushToHubCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        print(f\"Pushing model to the hub, epoch {trainer.current_epoch}\")\n",
    "        pl_module.model.push_to_hub(\"iarkh/donut-demo\",\n",
    "                                    commit_message=f\"Training in progress, epoch {trainer.current_epoch}\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(f\"Pushing model to the hub after training\")\n",
    "        pl_module.processor.push_to_hub(\"iarkh/donut-demo\",\n",
    "                                    commit_message=f\"Training done\")\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_edit_distance\", patience=3, verbose=False, mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        max_epochs=config.get(\"max_epochs\"),\n",
    "        val_check_interval=config.get(\"val_check_interval\"),\n",
    "        check_val_every_n_epoch=config.get(\"check_val_every_n_epoch\"),\n",
    "        gradient_clip_val=config.get(\"gradient_clip_val\"),\n",
    "        precision=16, # mixed precision\n",
    "        num_sanity_val_steps=0,\n",
    "        #logger=wandb_logger,\n",
    "        callbacks=[PushToHubCallback(), early_stop_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q donut-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"iarkh/donut-demo\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"iarkh/donut-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa1c0182ca445118f5a2029eec0231e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iarkh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from donut import JSONParseEvaluator\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "output_list = []\n",
    "accs = []\n",
    "\n",
    "dataset = load_dataset(\"naver-clova-ix/cord-v2\", split=\"validation\")\n",
    "\n",
    "for idx, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    # prepare encoder inputs\n",
    "    pixel_values = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    # prepare decoder inputs\n",
    "    task_prompt = \"<s_cord-v2>\"\n",
    "    decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "    decoder_input_ids = decoder_input_ids.to(device)\n",
    "\n",
    "    # generate sequence\n",
    "    outputs = model.generate(\n",
    "            pixel_values,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            max_length=model.decoder.config.max_position_embeddings,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id,\n",
    "            use_cache=True,\n",
    "            num_beams=1,\n",
    "            bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "\n",
    "    # turn into JSON\n",
    "    seq = processor.batch_decode(outputs.sequences)[0]\n",
    "    seq = seq.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
    "    seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "    seq = processor.token2json(seq)\n",
    "\n",
    "    ground_truth = json.loads(sample[\"ground_truth\"])\n",
    "    ground_truth = ground_truth[\"gt_parse\"]\n",
    "    evaluator = JSONParseEvaluator()\n",
    "    score = evaluator.cal_acc(seq, ground_truth)\n",
    "\n",
    "    accs.append(score)\n",
    "    output_list.append(seq)\n",
    "\n",
    "scores = {\"accuracies\": accs, \"mean_accuracy\": np.mean(accs)}\n",
    "print(scores, f\"length : {len(accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy:\", np.mean(accs))\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Check my picture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    file_path = fn\n",
    "\n",
    "image = Image.open(file_path)\n",
    "image_array = np.array(image)\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
